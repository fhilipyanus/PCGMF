{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"10Of1hZcdx62_EsFEUdTxbH44fuqK3R74","timestamp":1727539107329},{"file_id":"1XKX7BTzcTmSk3dldgCOwT8jCdzgEw7f7","timestamp":1727162677721},{"file_id":"1Yr64xAkSbn8CVFqSu62-cRi8fR9c2YKt","timestamp":1727099687164}],"gpuType":"T4","authorship_tag":"ABX9TyMnxgfhasHB27lpuGstXoU3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gp9mNWPSHL0T"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torchvision\n","from torchvision import datasets, transforms\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_digits\n","from torch.utils.data import DataLoader, TensorDataset, random_split\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import time\n","from tensorflow import keras\n","import psutil\n","import copy\n","device='cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n","])"],"metadata":{"id":"qftJ0nILHFhY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"],"metadata":{"id":"Cq0rCrWm6zbt","executionInfo":{"status":"ok","timestamp":1727531582541,"user_tz":-420,"elapsed":406,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b9e54906-e2b6-4647-c780-349f58e69330"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["# Flatten the images\n","x_train = x_train.reshape(-1, 28 * 28)\n","x_test = x_test.reshape(-1, 28 * 28)\n","\n","# Convert to tensors\n","x_train_tensor = torch.from_numpy(x_train).float().to(device)\n","y_train_tensor = torch.from_numpy(y_train).long().to(device)\n","x_test_tensor = torch.from_numpy(x_test).float().to(device)\n","y_test_tensor = torch.from_numpy(y_test).long().to(device)\n","\n","# Create the training dataset\n","train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n","\n","# Define the size of the validation set (e.g., 20% of the training set)\n","val_size = int(0.2 * len(train_dataset))\n","train_size = len(train_dataset) - val_size\n","\n","# Split the dataset into training and validation datasets\n","train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n","\n","# Create dataloaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)  # No shuffling for validation\n","test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"],"metadata":{"id":"ueiqAL0t-cXV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MLP_Mnist(nn.Module):\n","    def __init__(self):\n","        super(MLP_Mnist, self).__init__()\n","        self.fc1 = nn.Linear(784, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 10)\n","        self.relu1 = nn.ReLU()\n","        self.relu2 = nn.ReLU()\n","\n","    def forward(self, x):\n","        out = self.relu1(self.fc1(x))\n","        out = self.relu2(self.fc2(out))\n","        out = self.fc3(out)\n","        return out"],"metadata":{"id":"29nbpzTs7EV9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# UNFINISHED! ITS STILL NOT WHAT I WANT IT TO BE! I STILL DONT GET IT!\n","\n","class PCGMFTrainer:\n","    def __init__(self, model, pcriterion, poptimizer, perturbation_magnitude, patience=5, delta=0):\n","        self.model = model\n","        self.criterion = pcriterion\n","        self.optimizer = poptimizer\n","        self.perturbation_magnitude = perturbation_magnitude\n","        self.saved_models = []  # Store model states and their corresponding losses\n","        self.early_stopping = EarlyStopping(patience, delta)\n","        self.patience = patience\n","        self.delta = delta\n","        self.loss_global = 0\n","\n","    def train(self, train_loader, val_loader, epochs, perturbation_index):\n","        self.early_stopping = EarlyStopping(self.patience, self.delta)\n","        t1 = time.time()\n","        self.model.train()  # Set the model to training mode\n","        best_val_loss = float('inf')  # Track the best validation loss\n","\n","        for epoch in range(epochs):\n","            running_loss = 0.0\n","            for batch_idx, (data, target) in enumerate(train_loader):\n","                data, target = data.view(data.size(0), -1).to(device), target.to(device)  # Flatten the images\n","                self.optimizer.zero_grad()  # Zero the parameter gradients\n","                outputs = self.model(data)  # Forward pass\n","                loss = self.criterion(outputs, target)  # Calculate loss\n","                loss.backward()  # Backward pass\n","                self.optimizer.step()  # Optimize weights\n","                running_loss += loss.item()  # Accumulate loss\n","\n","            avg_loss = running_loss / len(train_loader)  # Calculate average loss for the epoch\n","            val_loss = calculate_validation_loss(self.model, val_loader, self.criterion)  # Validate\n","\n","            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}, Validation Loss: {val_loss:.4f}')\n","\n","            # Check for early stopping\n","            if self.early_stopping(val_loss):\n","                self.save_model(calculate_accuracy(model, val_loader))\n","                print(\"Early stopping triggered.\")\n","                break\n","\n","        t2 = time.time()\n","        print(f\"training time for pertubation {perturbation_index}: {t2 - t1:.2f}s\")\n","\n","    def save_model(self, accuracy):\n","        # Save the model state and its corresponding loss\n","        self.saved_models.append((copy.deepcopy(model), accuracy))\n","\n","    def apply_perturbation(self):\n","        with torch.no_grad():\n","            for param in self.model.parameters():\n","                noise = (torch.rand_like(param) * 2 - 1) * self.perturbation_magnitude\n","                param.add_(noise)\n","\n","    def train_with_perturbations(self, train_loader, val_loader, epochs, perturbations):\n","        # Train normally first and capture the final loss\n","        t1 = time.time()\n","        self.train(train_loader, val_loader, epochs, 0)\n","\n","        for _ in range(perturbations):\n","            self.apply_perturbation()  # Apply perturbation to model parameters\n","            self.train(train_loader, val_loader, epochs, _+1)  # Continue training with perturbations\n","        t2 = time.time()\n","        print(f\"total time = {t2-t1}\")\n","\n","    def evaluate(self):\n","        best_accuracy = 0\n","        iteration = 0\n","        best_accuracy_index = None\n","        if not self.saved_models:\n","            print(\"No saved models to evaluate.\")\n","            return\n","        for i in PCGMF.saved_models:\n","          if i[1]>best_accuracy:\n","            best_accuracy = i[1]\n","            best_accuracy_index = iteration\n","          iteration += 1\n","        print(f\"Best model is index {best_accuracy_index} with validation accuracy {best_accuracy}\")\n","        print(f\"Best model's test accuracy : {calculate_accuracy(PCGMF.saved_models[best_accuracy_index][0], test_loader)}\")\n"],"metadata":{"id":"yPXNT6xr8nNl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EarlyStopping:\n","    def __init__(self, patience=5, delta=0):\n","        self.patience = patience\n","        self.delta = delta\n","        self.best_loss = None\n","        self.counter = 0\n","\n","    def __call__(self, val_loss):\n","        if self.best_loss is None:\n","            self.best_loss = val_loss\n","        elif val_loss < self.best_loss - self.delta:\n","            self.best_loss = val_loss\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                return True  # Indicate convergence\n","        return False  # Continue training"],"metadata":{"id":"W2FrVhxdD6cS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_validation_loss(model, data_loader, criterion):\n","    model.eval()  # Set the model to evaluation mode\n","    total_loss = 0.0\n","    total_samples = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation for efficiency\n","        for data, target in data_loader:\n","            data = data.view(data.size(0), -1).to(device)  # Flatten the images\n","            target = target.to(device)\n","\n","            # Forward pass\n","            outputs = model(data)\n","\n","            # Calculate loss\n","            loss = criterion(outputs, target)\n","\n","            # Accumulate loss\n","            total_loss += loss.item() * data.size(0)  # Multiply by batch size to get total loss\n","            total_samples += data.size(0)  # Count total samples\n","\n","    average_loss = total_loss / total_samples  # Average loss over all samples\n","    return average_loss"],"metadata":{"id":"Ls0gOTUbE7vS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_accuracy(model, data_loader):\n","    model.eval()  # Set the model to evaluation mode\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation for efficiency\n","        for data, target in data_loader:\n","            data = data.view(data.size(0), -1).to(device)  # Flatten the images\n","            target = target.to(device)\n","\n","            # Forward pass\n","            outputs = model(data)\n","            _, predicted = torch.max(outputs.data, 1)  # Get the class with the highest probability\n","\n","            # Update correct and total counts\n","            total += target.size(0)\n","            correct += (predicted == target).sum().item()\n","\n","    accuracy = 100 * correct / total  # Calculate accuracy as a percentage\n","    return accuracy"],"metadata":{"id":"-5l0qQnECnrK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = MLP_Mnist().to(device)\n","#loss function and optimizer\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n","early_stopping = EarlyStopping(patience=5, delta=0.001)\n","\n","PCGMF = PCGMFTrainer(model, criterion, optimizer, perturbation_magnitude=0.01)"],"metadata":{"id":"iZaWxk5qBNNz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PCGMF.train_with_perturbations(train_loader, epochs=100, perturbations=3, val_loader=val_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O9Azx-_hB6l9","executionInfo":{"status":"ok","timestamp":1727539027386,"user_tz":-420,"elapsed":86738,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"outputId":"704a9742-442e-4ff3-c5da-e54bdf392f88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100], Loss: 0.5156, Validation Loss: 0.2962\n","Epoch [2/100], Loss: 0.2230, Validation Loss: 0.2313\n","Epoch [3/100], Loss: 0.1681, Validation Loss: 0.2061\n","Epoch [4/100], Loss: 0.1376, Validation Loss: 0.1807\n","Epoch [5/100], Loss: 0.1170, Validation Loss: 0.1741\n","Epoch [6/100], Loss: 0.1014, Validation Loss: 0.1602\n","Epoch [7/100], Loss: 0.0888, Validation Loss: 0.1540\n","Epoch [8/100], Loss: 0.0792, Validation Loss: 0.1571\n","Epoch [9/100], Loss: 0.0704, Validation Loss: 0.1478\n","Epoch [10/100], Loss: 0.0639, Validation Loss: 0.1522\n","Epoch [11/100], Loss: 0.0572, Validation Loss: 0.1526\n","Epoch [12/100], Loss: 0.0517, Validation Loss: 0.1453\n","Epoch [13/100], Loss: 0.0468, Validation Loss: 0.1442\n","Epoch [14/100], Loss: 0.0425, Validation Loss: 0.1474\n","Epoch [15/100], Loss: 0.0387, Validation Loss: 0.1390\n","Epoch [16/100], Loss: 0.0351, Validation Loss: 0.1398\n","Epoch [17/100], Loss: 0.0315, Validation Loss: 0.1375\n","Epoch [18/100], Loss: 0.0290, Validation Loss: 0.1375\n","Epoch [19/100], Loss: 0.0264, Validation Loss: 0.1357\n","Epoch [20/100], Loss: 0.0241, Validation Loss: 0.1358\n","Epoch [21/100], Loss: 0.0217, Validation Loss: 0.1447\n","Epoch [22/100], Loss: 0.0195, Validation Loss: 0.1440\n","Epoch [23/100], Loss: 0.0184, Validation Loss: 0.1384\n","Epoch [24/100], Loss: 0.0163, Validation Loss: 0.1418\n","Early stopping triggered.\n","training time for pertubation 0: 38.08s\n","Epoch [1/100], Loss: 0.0373, Validation Loss: 0.1531\n","Epoch [2/100], Loss: 0.0242, Validation Loss: 0.1522\n","Epoch [3/100], Loss: 0.0192, Validation Loss: 0.1508\n","Epoch [4/100], Loss: 0.0161, Validation Loss: 0.1491\n","Epoch [5/100], Loss: 0.0140, Validation Loss: 0.1487\n","Epoch [6/100], Loss: 0.0121, Validation Loss: 0.1495\n","Epoch [7/100], Loss: 0.0105, Validation Loss: 0.1522\n","Epoch [8/100], Loss: 0.0096, Validation Loss: 0.1503\n","Epoch [9/100], Loss: 0.0088, Validation Loss: 0.1508\n","Epoch [10/100], Loss: 0.0078, Validation Loss: 0.1530\n","Early stopping triggered.\n","training time for pertubation 1: 15.81s\n","Epoch [1/100], Loss: 0.0284, Validation Loss: 0.1640\n","Epoch [2/100], Loss: 0.0157, Validation Loss: 0.1657\n","Epoch [3/100], Loss: 0.0115, Validation Loss: 0.1624\n","Epoch [4/100], Loss: 0.0092, Validation Loss: 0.1613\n","Epoch [5/100], Loss: 0.0079, Validation Loss: 0.1623\n","Epoch [6/100], Loss: 0.0067, Validation Loss: 0.1611\n","Epoch [7/100], Loss: 0.0061, Validation Loss: 0.1613\n","Epoch [8/100], Loss: 0.0055, Validation Loss: 0.1622\n","Epoch [9/100], Loss: 0.0049, Validation Loss: 0.1625\n","Epoch [10/100], Loss: 0.0045, Validation Loss: 0.1633\n","Epoch [11/100], Loss: 0.0042, Validation Loss: 0.1647\n","Early stopping triggered.\n","training time for pertubation 2: 17.56s\n","Epoch [1/100], Loss: 0.0227, Validation Loss: 0.1784\n","Epoch [2/100], Loss: 0.0106, Validation Loss: 0.1759\n","Epoch [3/100], Loss: 0.0072, Validation Loss: 0.1719\n","Epoch [4/100], Loss: 0.0055, Validation Loss: 0.1705\n","Epoch [5/100], Loss: 0.0046, Validation Loss: 0.1707\n","Epoch [6/100], Loss: 0.0040, Validation Loss: 0.1708\n","Epoch [7/100], Loss: 0.0037, Validation Loss: 0.1707\n","Epoch [8/100], Loss: 0.0033, Validation Loss: 0.1721\n","Epoch [9/100], Loss: 0.0031, Validation Loss: 0.1732\n","Early stopping triggered.\n","training time for pertubation 3: 15.01s\n","total time = 86.46230292320251\n"]}]},{"cell_type":"code","source":["for i in PCGMF.saved_models:\n","  print(i[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FcuXbiiX9rnU","executionInfo":{"status":"ok","timestamp":1727539058414,"user_tz":-420,"elapsed":387,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"outputId":"fd50e979-bdee-4c8d-963a-ad3ea566d742"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["96.2\n","96.31666666666666\n","96.46666666666667\n","96.45\n"]}]},{"cell_type":"code","source":["PCGMF.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zV2O8GzPAj7J","executionInfo":{"status":"ok","timestamp":1727539060203,"user_tz":-420,"elapsed":416,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"outputId":"34baa021-f50b-4a3d-fe70-8d68dd9520fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best model is index 2 with validation accuracy 96.46666666666667\n","Best model's test accuracy : 96.98\n"]}]},{"cell_type":"code","source":["calculate_accuracy(PCGMF.saved_models[2][0], test_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yGJMWxOCqWJ","executionInfo":{"status":"ok","timestamp":1727538356666,"user_tz":-420,"elapsed":639,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"outputId":"c4977107-9179-4012-85db-e944f8a20feb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["96.92"]},"metadata":{},"execution_count":218}]}]}