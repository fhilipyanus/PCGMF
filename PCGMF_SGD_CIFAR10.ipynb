{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1XKX7BTzcTmSk3dldgCOwT8jCdzgEw7f7","timestamp":1727162677721},{"file_id":"1Yr64xAkSbn8CVFqSu62-cRi8fR9c2YKt","timestamp":1727099687164}],"gpuType":"T4","authorship_tag":"ABX9TyPsR/xRVxoZkfJDsEs03cb8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gp9mNWPSHL0T"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torchvision\n","from torchvision import datasets, transforms\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_digits\n","from torch.utils.data import DataLoader, TensorDataset, random_split\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import time\n","from tensorflow import keras\n","import psutil\n","import copy\n","device='cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n","])"],"metadata":{"id":"qftJ0nILHFhY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"],"metadata":{"id":"Cq0rCrWm6zbt","executionInfo":{"status":"ok","timestamp":1727540443772,"user_tz":-420,"elapsed":7549,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f244a457-1d42-45d8-d765-979dc9ad976c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["# Flatten the images to (batch_size, 3072)\n","x_train = x_train.reshape(-1, 32 * 32 * 3)  # Flattening for training data\n","x_test = x_test.reshape(-1, 32 * 32 * 3)    # Flattening for test data\n","\n","# Convert to tensors\n","x_train_tensor = torch.from_numpy(x_train).float().to(device)\n","y_train_tensor = torch.from_numpy(y_train).long().to(device).squeeze()  # Remove extra dimension\n","x_test_tensor = torch.from_numpy(x_test).float().to(device)\n","y_test_tensor = torch.from_numpy(y_test).long().to(device).squeeze()  # Remove extra dimension\n","\n","# Create the training dataset\n","train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n","\n","# Define the size of the validation set (e.g., 20% of the training set)\n","val_size = int(0.2 * len(train_dataset))\n","train_size = len(train_dataset) - val_size\n","\n","# Split the dataset into training and validation datasets\n","train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n","\n","# Create dataloaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)  # No shuffling for validation\n","test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"],"metadata":{"id":"ueiqAL0t-cXV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MLP_Cifar10(nn.Module):\n","    def __init__(self):\n","        super(MLP_Cifar10, self).__init__()\n","        self.fc1 = nn.Linear(3072, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 10)\n","        self.relu1 = nn.ReLU()\n","        self.relu2 = nn.ReLU()\n","\n","    def forward(self, x):\n","        out = self.relu1(self.fc1(x))\n","        out = self.relu2(self.fc2(out))\n","        out = self.fc3(out)\n","        return out"],"metadata":{"id":"29nbpzTs7EV9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PCGMFTrainer:\n","    def __init__(self, model, pcriterion, poptimizer, perturbation_magnitude, patience=5, delta=0):\n","        self.model = model\n","        self.criterion = pcriterion\n","        self.optimizer = poptimizer\n","        self.perturbation_magnitude = perturbation_magnitude\n","        self.saved_models = []  # Store model states and their corresponding losses\n","        self.early_stopping = EarlyStopping(patience, delta)\n","        self.patience = patience\n","        self.delta = delta\n","        self.loss_global = 0\n","\n","    def train(self, train_loader, val_loader, epochs, perturbation_index):\n","        self.early_stopping = EarlyStopping(self.patience, self.delta)\n","        t1 = time.time()\n","        self.model.train()  # Set the model to training mode\n","        best_val_loss = float('inf')  # Track the best validation loss\n","\n","        for epoch in range(epochs):\n","            running_loss = 0.0\n","            for batch_idx, (data, target) in enumerate(train_loader):\n","                data, target = data.view(data.size(0), -1).to(device), target.to(device)  # Flatten the images\n","                self.optimizer.zero_grad()  # Zero the parameter gradients\n","                outputs = self.model(data)  # Forward pass\n","                loss = self.criterion(outputs, target)  # Calculate loss\n","                loss.backward()  # Backward pass\n","                self.optimizer.step()  # Optimize weights\n","                running_loss += loss.item()  # Accumulate loss\n","\n","            avg_loss = running_loss / len(train_loader)  # Calculate average loss for the epoch\n","            val_loss = calculate_validation_loss(self.model, val_loader, self.criterion)  # Validate\n","\n","            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}, Validation Loss: {val_loss:.4f}')\n","\n","            # Check for early stopping\n","            if self.early_stopping(val_loss):\n","                self.save_model(calculate_accuracy(model, val_loader))\n","                print(\"Early stopping triggered.\")\n","                break\n","\n","        t2 = time.time()\n","        print(f\"training time for pertubation {perturbation_index}: {t2 - t1:.2f}s\")\n","\n","    def save_model(self, accuracy):\n","        # Save the model state and its corresponding loss\n","        self.saved_models.append((copy.deepcopy(model), accuracy))\n","\n","    def apply_perturbation(self):\n","        with torch.no_grad():\n","            for param in self.model.parameters():\n","                noise = (torch.rand_like(param) * 2 - 1) * self.perturbation_magnitude\n","                param.add_(noise)\n","\n","    def train_with_perturbations(self, train_loader, val_loader, epochs, perturbations):\n","        # Train normally first and capture the final loss\n","        t1 = time.time()\n","        self.train(train_loader, val_loader, epochs, 0)\n","\n","        for _ in range(perturbations):\n","            self.apply_perturbation()  # Apply perturbation to model parameters\n","            self.train(train_loader, val_loader, epochs, _+1)  # Continue training with perturbations\n","        t2 = time.time()\n","        print(f\"total time = {t2-t1}\")\n","\n","    def evaluate(self):\n","        best_accuracy = 0\n","        iteration = 0\n","        best_accuracy_index = None\n","        if not self.saved_models:\n","            print(\"No saved models to evaluate.\")\n","            return\n","        for i in PCGMF.saved_models:\n","          if i[1]>best_accuracy:\n","            best_accuracy = i[1]\n","            best_accuracy_index = iteration\n","          iteration += 1\n","        print(f\"Best model is index {best_accuracy_index} with validation accuracy {best_accuracy}\")\n","        print(f\"Best model's test accuracy : {calculate_accuracy(PCGMF.saved_models[best_accuracy_index][0], test_loader)}\")\n"],"metadata":{"id":"yPXNT6xr8nNl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EarlyStopping:\n","    def __init__(self, patience=5, delta=0):\n","        self.patience = patience\n","        self.delta = delta\n","        self.best_loss = None\n","        self.counter = 0\n","\n","    def __call__(self, val_loss):\n","        if self.best_loss is None:\n","            self.best_loss = val_loss\n","        elif val_loss < self.best_loss - self.delta:\n","            self.best_loss = val_loss\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                return True  # Indicate convergence\n","        return False  # Continue training"],"metadata":{"id":"W2FrVhxdD6cS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_validation_loss(model, data_loader, criterion):\n","    model.eval()  # Set the model to evaluation mode\n","    total_loss = 0.0\n","    total_samples = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation for efficiency\n","        for data, target in data_loader:\n","            data = data.view(data.size(0), -1).to(device)  # Flatten the images\n","            target = target.to(device)\n","\n","            # Forward pass\n","            outputs = model(data)\n","\n","            # Calculate loss\n","            loss = criterion(outputs, target)\n","\n","            # Accumulate loss\n","            total_loss += loss.item() * data.size(0)  # Multiply by batch size to get total loss\n","            total_samples += data.size(0)  # Count total samples\n","\n","    average_loss = total_loss / total_samples  # Average loss over all samples\n","    return average_loss"],"metadata":{"id":"Ls0gOTUbE7vS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_accuracy(model, data_loader):\n","    model.eval()  # Set the model to evaluation mode\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation for efficiency\n","        for data, target in data_loader:\n","            data = data.view(data.size(0), -1).to(device)  # Flatten the images\n","            target = target.to(device)\n","\n","            # Forward pass\n","            outputs = model(data)\n","            _, predicted = torch.max(outputs.data, 1)  # Get the class with the highest probability\n","\n","            # Update correct and total counts\n","            total += target.size(0)\n","            correct += (predicted == target).sum().item()\n","\n","    accuracy = 100 * correct / total  # Calculate accuracy as a percentage\n","    return accuracy"],"metadata":{"id":"-5l0qQnECnrK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = MLP_Cifar10().to(device)\n","#loss function and optimizer\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n","early_stopping = EarlyStopping(patience=10, delta=0.001)\n","\n","PCGMF = PCGMFTrainer(model, criterion, optimizer, perturbation_magnitude=0.02)"],"metadata":{"id":"iZaWxk5qBNNz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PCGMF.train_with_perturbations(train_loader, epochs=100, perturbations=3, val_loader=val_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O9Azx-_hB6l9","executionInfo":{"status":"ok","timestamp":1727541871838,"user_tz":-420,"elapsed":96583,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"outputId":"313cf5b5-c3b6-4d66-aedb-41e3364828fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100], Loss: 3.4932, Validation Loss: 2.3117\n","Epoch [2/100], Loss: 2.2179, Validation Loss: 2.3324\n","Epoch [3/100], Loss: 2.1975, Validation Loss: 2.1999\n","Epoch [4/100], Loss: 2.1643, Validation Loss: 2.1544\n","Epoch [5/100], Loss: 2.1289, Validation Loss: 2.0981\n","Epoch [6/100], Loss: 2.0320, Validation Loss: 1.9149\n","Epoch [7/100], Loss: 1.9019, Validation Loss: 1.8576\n","Epoch [8/100], Loss: 1.8419, Validation Loss: 1.8663\n","Epoch [9/100], Loss: 1.7961, Validation Loss: 1.7973\n","Epoch [10/100], Loss: 1.7571, Validation Loss: 1.8495\n","Epoch [11/100], Loss: 1.7300, Validation Loss: 1.7582\n","Epoch [12/100], Loss: 1.6912, Validation Loss: 1.6959\n","Epoch [13/100], Loss: 1.6633, Validation Loss: 1.6466\n","Epoch [14/100], Loss: 1.6292, Validation Loss: 1.6552\n","Epoch [15/100], Loss: 1.6027, Validation Loss: 1.6661\n","Epoch [16/100], Loss: 1.5800, Validation Loss: 1.6480\n","Epoch [17/100], Loss: 1.5611, Validation Loss: 1.6565\n","Epoch [18/100], Loss: 1.5344, Validation Loss: 1.6038\n","Epoch [19/100], Loss: 1.5215, Validation Loss: 1.7265\n","Epoch [20/100], Loss: 1.4979, Validation Loss: 1.5767\n","Epoch [21/100], Loss: 1.4776, Validation Loss: 1.5649\n","Epoch [22/100], Loss: 1.4689, Validation Loss: 1.5829\n","Epoch [23/100], Loss: 1.4514, Validation Loss: 1.5493\n","Epoch [24/100], Loss: 1.4309, Validation Loss: 1.5290\n","Epoch [25/100], Loss: 1.4181, Validation Loss: 1.5447\n","Epoch [26/100], Loss: 1.4040, Validation Loss: 1.5648\n","Epoch [27/100], Loss: 1.3921, Validation Loss: 1.5248\n","Epoch [28/100], Loss: 1.3769, Validation Loss: 1.5153\n","Epoch [29/100], Loss: 1.3614, Validation Loss: 1.5569\n","Epoch [30/100], Loss: 1.3506, Validation Loss: 1.4927\n","Epoch [31/100], Loss: 1.3346, Validation Loss: 1.5540\n","Epoch [32/100], Loss: 1.3313, Validation Loss: 1.5315\n","Epoch [33/100], Loss: 1.3168, Validation Loss: 1.5234\n","Epoch [34/100], Loss: 1.3006, Validation Loss: 1.4998\n","Epoch [35/100], Loss: 1.2908, Validation Loss: 1.5214\n","Early stopping triggered.\n","training time for pertubation 0: 48.46s\n","Epoch [1/100], Loss: 1.4997, Validation Loss: 1.5976\n","Epoch [2/100], Loss: 1.3871, Validation Loss: 1.6159\n","Epoch [3/100], Loss: 1.3507, Validation Loss: 1.5216\n","Epoch [4/100], Loss: 1.3253, Validation Loss: 1.5887\n","Epoch [5/100], Loss: 1.3056, Validation Loss: 1.5478\n","Epoch [6/100], Loss: 1.2900, Validation Loss: 1.5352\n","Epoch [7/100], Loss: 1.2755, Validation Loss: 1.5586\n","Epoch [8/100], Loss: 1.2565, Validation Loss: 1.5495\n","Early stopping triggered.\n","training time for pertubation 1: 10.64s\n","Epoch [1/100], Loss: 1.4676, Validation Loss: 1.5716\n","Epoch [2/100], Loss: 1.3493, Validation Loss: 1.5548\n","Epoch [3/100], Loss: 1.3116, Validation Loss: 1.6054\n","Epoch [4/100], Loss: 1.2827, Validation Loss: 1.5553\n","Epoch [5/100], Loss: 1.2652, Validation Loss: 1.5572\n","Epoch [6/100], Loss: 1.2453, Validation Loss: 1.5638\n","Epoch [7/100], Loss: 1.2285, Validation Loss: 1.5489\n","Epoch [8/100], Loss: 1.2187, Validation Loss: 1.5827\n","Epoch [9/100], Loss: 1.2005, Validation Loss: 1.6017\n","Epoch [10/100], Loss: 1.1891, Validation Loss: 1.5469\n","Epoch [11/100], Loss: 1.1774, Validation Loss: 1.5834\n","Epoch [12/100], Loss: 1.1608, Validation Loss: 1.5667\n","Epoch [13/100], Loss: 1.1560, Validation Loss: 1.5932\n","Epoch [14/100], Loss: 1.1435, Validation Loss: 1.5852\n","Epoch [15/100], Loss: 1.1369, Validation Loss: 1.5528\n","Early stopping triggered.\n","training time for pertubation 2: 20.78s\n","Epoch [1/100], Loss: 1.3875, Validation Loss: 1.6241\n","Epoch [2/100], Loss: 1.2610, Validation Loss: 1.6044\n","Epoch [3/100], Loss: 1.2200, Validation Loss: 1.6052\n","Epoch [4/100], Loss: 1.1913, Validation Loss: 1.6084\n","Epoch [5/100], Loss: 1.1679, Validation Loss: 1.5992\n","Epoch [6/100], Loss: 1.1482, Validation Loss: 1.5980\n","Epoch [7/100], Loss: 1.1324, Validation Loss: 1.5936\n","Epoch [8/100], Loss: 1.1180, Validation Loss: 1.6241\n","Epoch [9/100], Loss: 1.1074, Validation Loss: 1.6108\n","Epoch [10/100], Loss: 1.0954, Validation Loss: 1.6413\n","Epoch [11/100], Loss: 1.0821, Validation Loss: 1.6376\n","Epoch [12/100], Loss: 1.0743, Validation Loss: 1.6510\n","Early stopping triggered.\n","training time for pertubation 3: 16.31s\n","total time = 96.2023606300354\n"]}]},{"cell_type":"code","source":["perturbation_num = 0\n","for i in PCGMF.saved_models:\n","  print(f\"perturbation {perturbation_num}'s accuracy :{i[1]}\")\n","  perturbation_num +=1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FcuXbiiX9rnU","executionInfo":{"status":"ok","timestamp":1727542116521,"user_tz":-420,"elapsed":576,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"outputId":"e8d39937-0a91-4ac8-ec24-6e211fcdd3ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["perturbation 0's accuracy :47.6\n","perturbation 1's accuracy :47.43\n","perturbation 2's accuracy :47.97\n","perturbation 3's accuracy :47.58\n"]}]},{"cell_type":"code","source":["PCGMF.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zV2O8GzPAj7J","executionInfo":{"status":"ok","timestamp":1727542116940,"user_tz":-420,"elapsed":3,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"outputId":"7082ccc8-15ed-4882-909f-e0b669cd85ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best model is index 2 with validation accuracy 47.97\n","Best model's test accuracy : 47.64\n"]}]}]}