{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"10Of1hZcdx62_EsFEUdTxbH44fuqK3R74","timestamp":1727540361076},{"file_id":"1XKX7BTzcTmSk3dldgCOwT8jCdzgEw7f7","timestamp":1727162677721},{"file_id":"1Yr64xAkSbn8CVFqSu62-cRi8fR9c2YKt","timestamp":1727099687164}],"gpuType":"T4","authorship_tag":"ABX9TyOxhtpmG770cOZGTML55n2f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gp9mNWPSHL0T"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torchvision\n","from torchvision import datasets, transforms\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_digits\n","from torch.utils.data import DataLoader, TensorDataset, random_split\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import time\n","from tensorflow import keras\n","import psutil\n","import copy\n","device='cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n","])"],"metadata":{"id":"qftJ0nILHFhY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()"],"metadata":{"id":"Cq0rCrWm6zbt","executionInfo":{"status":"ok","timestamp":1727539159308,"user_tz":-420,"elapsed":804,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"040d7b51-76a7-451d-8ea7-97fb1334439f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["# Flatten the images\n","x_train = x_train.reshape(-1, 28 * 28)\n","x_test = x_test.reshape(-1, 28 * 28)\n","\n","# Convert to tensors\n","x_train_tensor = torch.from_numpy(x_train).float().to(device)\n","y_train_tensor = torch.from_numpy(y_train).long().to(device)\n","x_test_tensor = torch.from_numpy(x_test).float().to(device)\n","y_test_tensor = torch.from_numpy(y_test).long().to(device)\n","\n","# Create the training dataset\n","train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n","\n","# Define the size of the validation set (e.g., 20% of the training set)\n","val_size = int(0.2 * len(train_dataset))\n","train_size = len(train_dataset) - val_size\n","\n","# Split the dataset into training and validation datasets\n","train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n","\n","# Create dataloaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)  # No shuffling for validation\n","test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"],"metadata":{"id":"ueiqAL0t-cXV","executionInfo":{"status":"ok","timestamp":1727539161193,"user_tz":-420,"elapsed":376,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"49ac4fdf-75e2-4478-b2fd-51e2c7c88fdb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-241-8f83f1f3566b>:6: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n","  x_train_tensor = torch.from_numpy(x_train).float().to(device)\n"]}]},{"cell_type":"code","source":["class MLP_Mnist(nn.Module):\n","    def __init__(self):\n","        super(MLP_Mnist, self).__init__()\n","        self.fc1 = nn.Linear(784, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 10)\n","        self.relu1 = nn.ReLU()\n","        self.relu2 = nn.ReLU()\n","\n","    def forward(self, x):\n","        out = self.relu1(self.fc1(x))\n","        out = self.relu2(self.fc2(out))\n","        out = self.fc3(out)\n","        return out"],"metadata":{"id":"29nbpzTs7EV9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# UNFINISHED! ITS STILL NOT WHAT I WANT IT TO BE! I STILL DONT GET IT!\n","\n","class PCGMFTrainer:\n","    def __init__(self, model, pcriterion, poptimizer, perturbation_magnitude, patience=5, delta=0):\n","        self.model = model\n","        self.criterion = pcriterion\n","        self.optimizer = poptimizer\n","        self.perturbation_magnitude = perturbation_magnitude\n","        self.saved_models = []  # Store model states and their corresponding losses\n","        self.early_stopping = EarlyStopping(patience, delta)\n","        self.patience = patience\n","        self.delta = delta\n","        self.loss_global = 0\n","\n","    def train(self, train_loader, val_loader, epochs, perturbation_index):\n","        self.early_stopping = EarlyStopping(self.patience, self.delta)\n","        t1 = time.time()\n","        self.model.train()  # Set the model to training mode\n","        best_val_loss = float('inf')  # Track the best validation loss\n","\n","        for epoch in range(epochs):\n","            running_loss = 0.0\n","            for batch_idx, (data, target) in enumerate(train_loader):\n","                data, target = data.view(data.size(0), -1).to(device), target.to(device)  # Flatten the images\n","                self.optimizer.zero_grad()  # Zero the parameter gradients\n","                outputs = self.model(data)  # Forward pass\n","                loss = self.criterion(outputs, target)  # Calculate loss\n","                loss.backward()  # Backward pass\n","                self.optimizer.step()  # Optimize weights\n","                running_loss += loss.item()  # Accumulate loss\n","\n","            avg_loss = running_loss / len(train_loader)  # Calculate average loss for the epoch\n","            val_loss = calculate_validation_loss(self.model, val_loader, self.criterion)  # Validate\n","\n","            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}, Validation Loss: {val_loss:.4f}')\n","\n","            # Check for early stopping\n","            if self.early_stopping(val_loss):\n","                self.save_model(calculate_accuracy(model, val_loader))\n","                print(\"Early stopping triggered.\")\n","                break\n","\n","        t2 = time.time()\n","        print(f\"training time for pertubation {perturbation_index}: {t2 - t1:.2f}s\")\n","\n","    def save_model(self, accuracy):\n","        # Save the model state and its corresponding loss\n","        self.saved_models.append((copy.deepcopy(model), accuracy))\n","\n","    def apply_perturbation(self):\n","        with torch.no_grad():\n","            for param in self.model.parameters():\n","                noise = (torch.rand_like(param) * 2 - 1) * self.perturbation_magnitude\n","                param.add_(noise)\n","\n","    def train_with_perturbations(self, train_loader, val_loader, epochs, perturbations):\n","        # Train normally first and capture the final loss\n","        t1 = time.time()\n","        self.train(train_loader, val_loader, epochs, 0)\n","\n","        for _ in range(perturbations):\n","            self.apply_perturbation()  # Apply perturbation to model parameters\n","            self.train(train_loader, val_loader, epochs, _+1)  # Continue training with perturbations\n","        t2 = time.time()\n","        print(f\"total time = {t2-t1}\")\n","\n","    def evaluate(self):\n","        best_accuracy = 0\n","        iteration = 0\n","        best_accuracy_index = None\n","        if not self.saved_models:\n","            print(\"No saved models to evaluate.\")\n","            return\n","        for i in PCGMF.saved_models:\n","          if i[1]>best_accuracy:\n","            best_accuracy = i[1]\n","            best_accuracy_index = iteration\n","          iteration += 1\n","        print(f\"Best model is index {best_accuracy_index} with validation accuracy {best_accuracy}\")\n","        print(f\"Best model's test accuracy : {calculate_accuracy(PCGMF.saved_models[best_accuracy_index][0], test_loader)}\")\n"],"metadata":{"id":"yPXNT6xr8nNl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EarlyStopping:\n","    def __init__(self, patience=5, delta=0):\n","        self.patience = patience\n","        self.delta = delta\n","        self.best_loss = None\n","        self.counter = 0\n","\n","    def __call__(self, val_loss):\n","        if self.best_loss is None:\n","            self.best_loss = val_loss\n","        elif val_loss < self.best_loss - self.delta:\n","            self.best_loss = val_loss\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                return True  # Indicate convergence\n","        return False  # Continue training"],"metadata":{"id":"W2FrVhxdD6cS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_validation_loss(model, data_loader, criterion):\n","    model.eval()  # Set the model to evaluation mode\n","    total_loss = 0.0\n","    total_samples = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation for efficiency\n","        for data, target in data_loader:\n","            data = data.view(data.size(0), -1).to(device)  # Flatten the images\n","            target = target.to(device)\n","\n","            # Forward pass\n","            outputs = model(data)\n","\n","            # Calculate loss\n","            loss = criterion(outputs, target)\n","\n","            # Accumulate loss\n","            total_loss += loss.item() * data.size(0)  # Multiply by batch size to get total loss\n","            total_samples += data.size(0)  # Count total samples\n","\n","    average_loss = total_loss / total_samples  # Average loss over all samples\n","    return average_loss"],"metadata":{"id":"Ls0gOTUbE7vS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_accuracy(model, data_loader):\n","    model.eval()  # Set the model to evaluation mode\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation for efficiency\n","        for data, target in data_loader:\n","            data = data.view(data.size(0), -1).to(device)  # Flatten the images\n","            target = target.to(device)\n","\n","            # Forward pass\n","            outputs = model(data)\n","            _, predicted = torch.max(outputs.data, 1)  # Get the class with the highest probability\n","\n","            # Update correct and total counts\n","            total += target.size(0)\n","            correct += (predicted == target).sum().item()\n","\n","    accuracy = 100 * correct / total  # Calculate accuracy as a percentage\n","    return accuracy"],"metadata":{"id":"-5l0qQnECnrK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = MLP_Mnist().to(device)\n","#loss function and optimizer\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n","early_stopping = EarlyStopping(patience=5, delta=0.001)\n","\n","PCGMF = PCGMFTrainer(model, criterion, optimizer, perturbation_magnitude=0.01)"],"metadata":{"id":"iZaWxk5qBNNz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PCGMF.train_with_perturbations(train_loader, epochs=100, perturbations=3, val_loader=val_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O9Azx-_hB6l9","executionInfo":{"status":"ok","timestamp":1727540199067,"user_tz":-420,"elapsed":90755,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"outputId":"cc60c64d-1e89-444c-99c0-d4692327b588"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100], Loss: 0.7984, Validation Loss: 0.5033\n","Epoch [2/100], Loss: 0.4823, Validation Loss: 0.4536\n","Epoch [3/100], Loss: 0.4341, Validation Loss: 0.4267\n","Epoch [4/100], Loss: 0.4029, Validation Loss: 0.4075\n","Epoch [5/100], Loss: 0.3811, Validation Loss: 0.3886\n","Epoch [6/100], Loss: 0.3637, Validation Loss: 0.4157\n","Epoch [7/100], Loss: 0.3485, Validation Loss: 0.3777\n","Epoch [8/100], Loss: 0.3368, Validation Loss: 0.3819\n","Epoch [9/100], Loss: 0.3253, Validation Loss: 0.3686\n","Epoch [10/100], Loss: 0.3161, Validation Loss: 0.3778\n","Epoch [11/100], Loss: 0.3086, Validation Loss: 0.3722\n","Epoch [12/100], Loss: 0.3003, Validation Loss: 0.3530\n","Epoch [13/100], Loss: 0.2938, Validation Loss: 0.3520\n","Epoch [14/100], Loss: 0.2874, Validation Loss: 0.3629\n","Epoch [15/100], Loss: 0.2805, Validation Loss: 0.3562\n","Epoch [16/100], Loss: 0.2769, Validation Loss: 0.3556\n","Epoch [17/100], Loss: 0.2704, Validation Loss: 0.3508\n","Epoch [18/100], Loss: 0.2663, Validation Loss: 0.3473\n","Epoch [19/100], Loss: 0.2593, Validation Loss: 0.3458\n","Epoch [20/100], Loss: 0.2548, Validation Loss: 0.3385\n","Epoch [21/100], Loss: 0.2503, Validation Loss: 0.3489\n","Epoch [22/100], Loss: 0.2467, Validation Loss: 0.3512\n","Epoch [23/100], Loss: 0.2434, Validation Loss: 0.3567\n","Epoch [24/100], Loss: 0.2390, Validation Loss: 0.3449\n","Epoch [25/100], Loss: 0.2336, Validation Loss: 0.3433\n","Early stopping triggered.\n","training time for pertubation 0: 39.74s\n","Epoch [1/100], Loss: 0.2533, Validation Loss: 0.3468\n","Epoch [2/100], Loss: 0.2399, Validation Loss: 0.3724\n","Epoch [3/100], Loss: 0.2347, Validation Loss: 0.3502\n","Epoch [4/100], Loss: 0.2287, Validation Loss: 0.3415\n","Epoch [5/100], Loss: 0.2246, Validation Loss: 0.3414\n","Epoch [6/100], Loss: 0.2207, Validation Loss: 0.3432\n","Epoch [7/100], Loss: 0.2173, Validation Loss: 0.3494\n","Epoch [8/100], Loss: 0.2118, Validation Loss: 0.3578\n","Epoch [9/100], Loss: 0.2097, Validation Loss: 0.3431\n","Epoch [10/100], Loss: 0.2062, Validation Loss: 0.3623\n","Early stopping triggered.\n","training time for pertubation 1: 15.85s\n","Epoch [1/100], Loss: 0.2251, Validation Loss: 0.3585\n","Epoch [2/100], Loss: 0.2134, Validation Loss: 0.3618\n","Epoch [3/100], Loss: 0.2074, Validation Loss: 0.3555\n","Epoch [4/100], Loss: 0.2028, Validation Loss: 0.3496\n","Epoch [5/100], Loss: 0.1992, Validation Loss: 0.3574\n","Epoch [6/100], Loss: 0.1951, Validation Loss: 0.3541\n","Epoch [7/100], Loss: 0.1909, Validation Loss: 0.3720\n","Epoch [8/100], Loss: 0.1904, Validation Loss: 0.3510\n","Epoch [9/100], Loss: 0.1872, Validation Loss: 0.3594\n","Early stopping triggered.\n","training time for pertubation 2: 14.33s\n","Epoch [1/100], Loss: 0.2077, Validation Loss: 0.3685\n","Epoch [2/100], Loss: 0.1955, Validation Loss: 0.3649\n","Epoch [3/100], Loss: 0.1880, Validation Loss: 0.3758\n","Epoch [4/100], Loss: 0.1846, Validation Loss: 0.3597\n","Epoch [5/100], Loss: 0.1804, Validation Loss: 0.3807\n","Epoch [6/100], Loss: 0.1772, Validation Loss: 0.3704\n","Epoch [7/100], Loss: 0.1737, Validation Loss: 0.3709\n","Epoch [8/100], Loss: 0.1716, Validation Loss: 0.3564\n","Epoch [9/100], Loss: 0.1679, Validation Loss: 0.3942\n","Epoch [10/100], Loss: 0.1665, Validation Loss: 0.3836\n","Epoch [11/100], Loss: 0.1643, Validation Loss: 0.4012\n","Epoch [12/100], Loss: 0.1608, Validation Loss: 0.3786\n","Epoch [13/100], Loss: 0.1588, Validation Loss: 0.3905\n","Early stopping triggered.\n","training time for pertubation 3: 21.08s\n","total time = 91.0125892162323\n"]}]},{"cell_type":"code","source":["for i in PCGMF.saved_models:\n","  print(i[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FcuXbiiX9rnU","executionInfo":{"status":"ok","timestamp":1727540205345,"user_tz":-420,"elapsed":382,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"outputId":"61567095-473e-4406-fcf3-aab1b9a55a72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["87.925\n","87.51666666666667\n","88.2\n","87.99166666666666\n"]}]},{"cell_type":"code","source":["PCGMF.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zV2O8GzPAj7J","executionInfo":{"status":"ok","timestamp":1727540277649,"user_tz":-420,"elapsed":845,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"outputId":"26988d39-a75a-4e62-9cbc-150607f64e6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best model is index 2 with validation accuracy 88.2\n","Best model's test accuracy : 86.9\n"]}]},{"cell_type":"code","source":["calculate_accuracy(PCGMF.saved_models[3][0], test_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yGJMWxOCqWJ","executionInfo":{"status":"ok","timestamp":1727539589691,"user_tz":-420,"elapsed":400,"user":{"displayName":"Fhilip Yanus","userId":"02752878488140676545"}},"outputId":"f1ff55b0-4960-43bc-cc51-8c2d4b7d32cb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["87.0"]},"metadata":{},"execution_count":256}]}]}